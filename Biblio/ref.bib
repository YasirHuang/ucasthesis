%---------------------------------------------------------------------------%
%-                                                                         -%
%-                             Bibliography                                -%
%-                                                                         -%
%---------------------------------------------------------------------------%
@book{wikibook2014latex,
    title={http://en.wikibooks.org/wiki/LaTeX},
    author={Wikibook},
    year={2014},
    publisher={On-line Resources}
}
@book{lamport1986document,
    title={Document Preparation System},
    author={Lamport, Leslie},
    year={1986},
    publisher={Addison-Wesley Reading, MA}
}
@article{chen2005zhulu,
    title={著录文后参考文献的规则及注意事项},
    author={陈浩元},
    key={Chen Hao Yuan},
    journal={编辑学报},
    volume={17},
    number={6},
    pages={413--415},
    year={2005}
}
@book{chu2004tushu,
    title={图书馆数字参考咨询服务研究},
    author={初景利},
    key={Chu Jing Li},
    year={2004},
    address={北京},
    publisher={北京图书馆出版社}
}
@article{stamerjohanns2009mathml,
    title={{MathML}-aware article conversion from {LaTeX}},
    author={Stamerjohanns, Heinrich and Ginev, Deyan and David, Catalin and Misev, Dimitar and Zamdzhiev, Vladimir and Kohlhase, Michael},
    journal={Towards a Digital Mathematics Library},
    volume={16},
    number={2},
    pages={109--120},
    year={2009},
    publisher={Masaryk University Press}
}
@article{betts2005aging,
    title={Aging reduces center-surround antagonism in visual motion processing},
    author={Betts, Lisa R and Taylor, Christopher P},
    journal={Neuron},
    volume={45},
    number={3},
    pages={361--366},
    year={2005},
    publisher={Elsevier}
}

@article{bravo1990comparative,
    title={Comparative study of visual inter and intrahemispheric cortico-cortical connections in five native Chilean rodents},
    author={Bravo, Hermes and Olavarria, Jaime},
    journal={Anatomy and embryology},
    volume={181},
    number={1},
    pages={67--73},
    year={1990},
    publisher={Springer}
}
@book{hls2012jinji,
    author       = {哈里森·沃尔德伦},
    key          = {Haliseng Woerdelun},
    translator   = {谢远涛},
    title        = {经济数学与金融数学},
    address      = {北京},
    publisher    = {中国人民大学出版社},
    year         = {2012},
    pages        = {235--236},
}
@proceedings{niu2013zonghe,
    editor       = {牛志明 and 斯温兰德 and 雷光春},
    key          = {Niu Zhi Ming Siwenlande Lei Guang Chun},
    title        = {综合湿地管理国际研讨会论文集},
    address      = {北京},
    publisher    = {海洋出版社},
    year         = {2013},
}
@incollection{chen1980zhongguo,
    author       = {陈晋镳 and 张惠民 and 朱士兴 and 赵震 and
        王振刚},
    key          = {Chen Jing Ao Zhang Hui Ming Zhu Shi Xing Zhao Zhen Wang Zhen Gang},
    title        = {蓟县震旦亚界研究},
    editor       = {中国地质科学院天津地质矿产研究所},
    booktitle    = {中国震旦亚界},
    address      = {天津},
    publisher    = {天津科学技术出版社},
    year         = {1980},
    pages        = {56--114},
}
@article{yuan2012lana,
    author       = {袁训来 and 陈哲 and 肖书海},
    key          = {Yuan xun lai Chen zhe Xiao shu Hai},
    title        = {蓝田生物群: 一个认识多细胞生物起源和早期演化的新窗口 -- 篇一},
    journal      = {科学通报},
    year         = {2012},
    volume       = {57},
    number       = {34},
    pages        = {3219},
}
@article{yuan2012lanb,
    author       = {袁训来 and 陈哲 and 肖书海},
    key          = {Yuan xun lai Chen zhe Xiao shu Hai},
    title        = {蓝田生物群: 一个认识多细胞生物起源和早期演化的新窗口 -- 篇二},
    journal      = {科学通报},
    year         = {2012},
    volume       = {57},
    number       = {34},
    pages        = {3219},
}
@article{yuan2012lanc,
    author       = {袁训来 and 陈哲 and 肖书海},
    key          = {Yuan xun lai Chen zhe Xiao shu Hai},
    title        = {蓝田生物群: 一个认识多细胞生物起源和早期演化的新窗口 -- 篇三},
    journal      = {科学通报},
    year         = {2012},
    volume       = {57},
    number       = {34},
    pages        = {3219},
}
@article{walls2013drought,
    author       = {Walls, Susan C. and Barichivich, William J. and Brown, Mary
        E.},
    title        = {Drought, deluge and declines: the impact of precipitation
        extremes on amphibians in a changing climate},
    journal      = {Biology},
    year         = {2013},
    volume       = {2},
    number       = {1},
    pages        = {399--418},
    urldate      = {2013-11-04},
    url          = {http://www.mdpi.com/2079-7737/2/1/399},
    doi          = {10.3390/biology2010399},
}
@article{Bohan1928,
    author = { ボハン, デ},
    title = { 過去及び現在に於ける英国と会 },
    journal = { 日本時報 },
    year = { 1928 },
    volume = { 17 },
    pages = { 5-9 },
    edition = { 9 },
    hyphenation = { japanese },
    language = { japanese }
}

@article{Dubrovin1906,
    author = { Дубровин, А. И },
    title = { Открытое письмо Председателя Главного Совета Союза Русского Народа Санкт-Петербургскому Антонию, Первенствующему члену Священного Синода },
    journal = { Вече },
    year = { 1906 },
    volume = {  },
    edition = { 97 },
    month = { 7 дек. 1906 },
    pages = { 1-3 },
    hyphenation = { russian },
    language = { russian }
}

%1
@article{1_DBLP:journals/corr/SutskeverVL14,
  author    = {Ilya Sutskever and
               Oriol Vinyals and
               Quoc V. Le},
  title     = {Sequence to Sequence Learning with Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1409.3215},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.3215},
  eprinttype = {arXiv},
  eprint    = {1409.3215},
  timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SutskeverVL14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%2
@inproceedings{2_cho-etal-2014-learning,
    title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
    author = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Gulcehre, Caglar  and
      Bahdanau, Dzmitry  and
      Bougares, Fethi  and
      Schwenk, Holger  and
      Bengio, Yoshua},
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1179",
    doi = "10.3115/v1/D14-1179",
    pages = "1724--1734",
}
%3
@inproceedings{3_DBLP:journals/corr/BahdanauCB14,
  author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1409.0473},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%4
@inproceedings{4_luong-etal-2015-effective,
    title = "Effective Approaches to Attention-based Neural Machine Translation",
    author = "Luong, Thang  and
      Pham, Hieu  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1166",
    doi = "10.18653/v1/D15-1166",
    pages = "1412--1421",
}
%5
@article{5_DBLP:journals/corr/VaswaniSPUJGKP17,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%6
@article{6_DBLP:journals/corr/GehringAGYD17,
  author    = {Jonas Gehring and
               Michael Auli and
               David Grangier and
               Denis Yarats and
               Yann N. Dauphin},
  title     = {Convolutional Sequence to Sequence Learning},
  journal   = {CoRR},
  volume    = {abs/1705.03122},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.03122},
  eprinttype = {arXiv},
  eprint    = {1705.03122},
  timestamp = {Mon, 13 Aug 2018 16:48:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/GehringAGYD17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%7
@inproceedings{7_DBLP:conf/naacl/DevlinCLT19,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  editor    = {Jill Burstein and
               Christy Doran and
               Thamar Solorio},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {4171--4186},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/n19-1423},
  doi       = {10.18653/v1/n19-1423},
  timestamp = {Mon, 26 Sep 2022 12:21:55 +0200},
  biburl    = {https://dblp.org/rec/conf/naacl/DevlinCLT19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%8
@article{8_DBLP:journals/corr/abs-1803-02155,
  author    = {Peter Shaw and
               Jakob Uszkoreit and
               Ashish Vaswani},
  title     = {Self-Attention with Relative Position Representations},
  journal   = {CoRR},
  volume    = {abs/1803.02155},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.02155},
  eprinttype = {arXiv},
  eprint    = {1803.02155},
  timestamp = {Mon, 13 Aug 2018 16:46:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-02155.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%9
@article{9_DBLP:journals/corr/abs-1901-02860,
  author    = {Zihang Dai and
               Zhilin Yang and
               Yiming Yang and
               Jaime G. Carbonell and
               Quoc V. Le and
               Ruslan Salakhutdinov},
  title     = {Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context},
  journal   = {CoRR},
  volume    = {abs/1901.02860},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.02860},
  eprinttype = {arXiv},
  eprint    = {1901.02860},
  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-02860.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%10
@article{10_DBLP:journals/corr/abs-1802-05751,
  author    = {Niki Parmar and
               Ashish Vaswani and
               Jakob Uszkoreit and
               Lukasz Kaiser and
               Noam Shazeer and
               Alexander Ku},
  title     = {Image Transformer},
  journal   = {CoRR},
  volume    = {abs/1802.05751},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.05751},
  eprinttype = {arXiv},
  eprint    = {1802.05751},
  timestamp = {Mon, 13 Aug 2018 16:48:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1802-05751.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%11
@inproceedings{11_DBLP:conf/iclr/DosovitskiyB0WZ21,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=YicbFdNTTy},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DosovitskiyB0WZ21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%12
@inproceedings{12_DBLP:conf/iccv/LiuL00W0LG21,
  author    = {Ze Liu and
               Yutong Lin and
               Yue Cao and
               Han Hu and
               Yixuan Wei and
               Zheng Zhang and
               Stephen Lin and
               Baining Guo},
  title     = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  booktitle = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
               2021, Montreal, QC, Canada, October 10-17, 2021},
  pages     = {9992--10002},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICCV48922.2021.00986},
  doi       = {10.1109/ICCV48922.2021.00986},
  timestamp = {Thu, 19 May 2022 16:00:58 +0200},
  biburl    = {https://dblp.org/rec/conf/iccv/LiuL00W0LG21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%13
@inproceedings{13_DBLP:conf/iccv/0007CWYSJTFY21,
  author    = {Li Yuan and
               Yunpeng Chen and
               Tao Wang and
               Weihao Yu and
               Yujun Shi and
               Zihang Jiang and
               Francis E. H. Tay and
               Jiashi Feng and
               Shuicheng Yan},
  title     = {Tokens-to-Token ViT: Training Vision Transformers from Scratch on
               ImageNet},
  booktitle = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
               2021, Montreal, QC, Canada, October 10-17, 2021},
  pages     = {538--547},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICCV48922.2021.00060},
  doi       = {10.1109/ICCV48922.2021.00060},
  timestamp = {Mon, 04 Apr 2022 16:15:33 +0200},
  biburl    = {https://dblp.org/rec/conf/iccv/0007CWYSJTFY21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%14
@inproceedings{14_DBLP:conf/nips/LuBPL19,
  author    = {Jiasen Lu and
               Dhruv Batra and
               Devi Parikh and
               Stefan Lee},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations
               for Vision-and-Language Tasks},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {13--23},
  year      = {2019},
  url       = {https://proceedings.neurips.cc/paper/2019/hash/c74d97b01eae257e44aa9d5bade97baf-Abstract.html},
  timestamp = {Mon, 16 May 2022 15:41:51 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/LuBPL19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%15
@inproceedings{15_DBLP:conf/eccv/ChenLYK0G0020,
  author    = {Yen{-}Chun Chen and
               Linjie Li and
               Licheng Yu and
               Ahmed El Kholy and
               Faisal Ahmed and
               Zhe Gan and
               Yu Cheng and
               Jingjing Liu},
  editor    = {Andrea Vedaldi and
               Horst Bischof and
               Thomas Brox and
               Jan{-}Michael Frahm},
  title     = {{UNITER:} UNiversal Image-TExt Representation Learning},
  booktitle = {Computer Vision - {ECCV} 2020 - 16th European Conference, Glasgow,
               UK, August 23-28, 2020, Proceedings, Part {XXX}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12375},
  pages     = {104--120},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-58577-8\_7},
  doi       = {10.1007/978-3-030-58577-8\_7},
  timestamp = {Sun, 02 Oct 2022 15:59:30 +0200},
  biburl    = {https://dblp.org/rec/conf/eccv/ChenLYK0G0020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%16
@article{16_DBLP:journals/corr/abs-2004-00849,
  author    = {Zhicheng Huang and
               Zhaoyang Zeng and
               Bei Liu and
               Dongmei Fu and
               Jianlong Fu},
  title     = {Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers},
  journal   = {CoRR},
  volume    = {abs/2004.00849},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.00849},
  eprinttype = {arXiv},
  eprint    = {2004.00849},
  timestamp = {Fri, 13 Aug 2021 14:56:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-00849.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%17
@inproceedings{17_DBLP:conf/icml/KimSK21,
  author    = {Wonjae Kim and
               Bokyung Son and
               Ildoo Kim},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {ViLT: Vision-and-Language Transformer Without Convolution or Region
               Supervision},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {5583--5594},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/kim21k.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/KimSK21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%18
@inproceedings{18_DBLP:conf/emnlp/CalixtoL17,
  author    = {Iacer Calixto and
               Qun Liu},
  editor    = {Martha Palmer and
               Rebecca Hwa and
               Sebastian Riedel},
  title     = {Incorporating Global Visual Features into Attention-based Neural Machine
               Translation},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2017, Copenhagen, Denmark, September
               9-11, 2017},
  pages     = {992--1003},
  publisher = {Association for Computational Linguistics},
  year      = {2017},
  url       = {https://doi.org/10.18653/v1/d17-1105},
  doi       = {10.18653/v1/d17-1105},
  timestamp = {Thu, 02 Sep 2021 09:00:27 +0200},
  biburl    = {https://dblp.org/rec/conf/emnlp/CalixtoL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%19
@inproceedings{19_DBLP:conf/acl/CalixtoRA19,
  author    = {Iacer Calixto and
               Miguel Rios and
               Wilker Aziz},
  editor    = {Anna Korhonen and
               David R. Traum and
               Llu{\'{\i}}s M{\`{a}}rquez},
  title     = {Latent Variable Model for Multi-modal Translation},
  booktitle = {Proceedings of the 57th Conference of the Association for Computational
               Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
               Volume 1: Long Papers},
  pages     = {6392--6405},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/p19-1642},
  doi       = {10.18653/v1/p19-1642},
  timestamp = {Sun, 02 Oct 2022 15:53:42 +0200},
  biburl    = {https://dblp.org/rec/conf/acl/CalixtoRA19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%20
@inproceedings{20_wu-etal-2021-good,
    title = "Good for Misconceived Reasons: An Empirical Revisiting on the Need for Visual Context in Multimodal Machine Translation",
    author = "Wu, Zhiyong  and
      Kong, Lingpeng  and
      Bi, Wei  and
      Li, Xiang  and
      Kao, Ben",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.480",
    doi = "10.18653/v1/2021.acl-long.480",
    pages = "6153--6166",
    abstract = "A neural multimodal machine translation (MMT) system is one that aims to perform better translation by extending conventional text-only translation models with multimodal information. Many recent studies report improvements when equipping their models with the multimodal module, despite the controversy of whether such improvements indeed come from the multimodal part. We revisit the contribution of multimodal information in MMT by devising two interpretable MMT models. To our surprise, although our models replicate similar gains as recently developed multimodal-integrated systems achieved, our models learn to ignore the multimodal information. Upon further investigation, we discover that the improvements achieved by the multimodal models over text-only counterparts are in fact results of the regularization effect. We report empirical findings that highlight the importance of MMT models{'} interpretability, and discuss how our findings will benefit future research.",
}

%21
@inproceedings{21_dutta-chowdhury-elliott-2019-understanding,
    title = "Understanding the Effect of Textual Adversaries in Multimodal Machine Translation",
    author = "Dutta Chowdhury, Koel  and
      Elliott, Desmond",
    booktitle = "Proceedings of the Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-6406",
    doi = "10.18653/v1/D19-6406",
    pages = "35--40",
    abstract = "It is assumed that multimodal machine translation systems are better than text-only systems at translating phrases that have a direct correspondence in the image. This assumption has been challenged in experiments demonstrating that state-of-the-art multimodal systems perform equally well in the presence of randomly selected images, but, more recently, it has been shown that masking entities from the source language sentence during training can help to overcome this problem. In this paper, we conduct experiments with both visual and textual adversaries in order to understand the role of incorrect textual inputs to such systems. Our results show that when the source language sentence contains mistakes, multimodal translation systems do not leverage the additional visual signal to produce the correct translation. We also find that the degradation of translation performance caused by textual adversaries is significantly higher than by visual adversaries.",
}
%22
@inproceedings{22_li-etal-2021-vision,
    title = "Vision Matters When It Should: Sanity Checking Multimodal Machine Translation Models",
    author = "Li, Jiaoda  and
      Ataman, Duygu  and
      Sennrich, Rico",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.673",
    doi = "10.18653/v1/2021.emnlp-main.673",
    pages = "8556--8562",
    abstract = "Multimodal machine translation (MMT) systems have been shown to outperform their text-only neural machine translation (NMT) counterparts when visual context is available. However, recent studies have also shown that the performance of MMT models is only marginally impacted when the associated image is replaced with an unrelated image or noise, which suggests that the visual context might not be exploited by the model at all. We hypothesize that this might be caused by the nature of the commonly used evaluation benchmark, also known as Multi30K, where the translations of image captions were prepared without actually showing the images to human translators. In this paper, we present a qualitative study that examines the role of datasets in stimulating the leverage of visual modality and we propose methods to highlight the importance of visual signals in the datasets which demonstrate improvements in reliance of models on the source images. Our findings suggest the research on effective MMT architectures is currently impaired by the lack of suitable datasets and careful consideration must be taken in creation of future MMT datasets, for which we also provide useful insights.",
}
%23
@inproceedings{23_elliott-2018-adversarial,
    title = "Adversarial Evaluation of Multimodal Machine Translation",
    author = "Elliott, Desmond",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1329",
    doi = "10.18653/v1/D18-1329",
    pages = "2974--2978",
    abstract = "The promise of combining language and vision in multimodal machine translation is that systems will produce better translations by leveraging the image data. However, the evidence surrounding whether the images are useful is unconvincing due to inconsistencies between text-similarity metrics and human judgements. We present an adversarial evaluation to directly examine the utility of the image data in this task. Our evaluation tests whether systems perform better when paired with congruent images or incongruent images. This evaluation shows that only one out of three publicly available systems is sensitive to this perturbation of the data. We recommend that multimodal translation systems should be able to pass this sanity check in the future.",
}
%24
@inproceedings{24_DBLP:conf/iccv/YangGWHYL19,
  author    = {Zhengyuan Yang and
               Boqing Gong and
               Liwei Wang and
               Wenbing Huang and
               Dong Yu and
               Jiebo Luo},
  title     = {A Fast and Accurate One-Stage Approach to Visual Grounding},
  booktitle = {2019 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
               2019, Seoul, Korea (South), October 27 - November 2, 2019},
  pages     = {4682--4692},
  publisher = {{IEEE}},
  year      = {2019},
  url       = {https://doi.org/10.1109/ICCV.2019.00478},
  doi       = {10.1109/ICCV.2019.00478},
  timestamp = {Wed, 07 Dec 2022 23:07:05 +0100},
  biburl    = {https://dblp.org/rec/conf/iccv/YangGWHYL19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%25
@inproceedings{25_DBLP:conf/naacl/DevlinCLT19,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  editor    = {Jill Burstein and
               Christy Doran and
               Thamar Solorio},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {4171--4186},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/n19-1423},
  doi       = {10.18653/v1/n19-1423},
  timestamp = {Mon, 26 Sep 2022 12:21:55 +0200},
  biburl    = {https://dblp.org/rec/conf/naacl/DevlinCLT19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%26
@article{26_DBLP:journals/corr/abs-1804-02767,
  author    = {Joseph Redmon and
               Ali Farhadi},
  title     = {YOLOv3: An Incremental Improvement},
  journal   = {CoRR},
  volume    = {abs/1804.02767},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.02767},
  eprinttype = {arXiv},
  eprint    = {1804.02767},
  timestamp = {Mon, 13 Aug 2018 16:48:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-02767.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%27
@inproceedings{27_sennrich-etal-2016-neural,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725",
}
%28
@article{28_DBLP:journals/corr/WuSCLNMKCGMKSJL16,
  author    = {Yonghui Wu and
               Mike Schuster and
               Zhifeng Chen and
               Quoc V. Le and
               Mohammad Norouzi and
               Wolfgang Macherey and
               Maxim Krikun and
               Yuan Cao and
               Qin Gao and
               Klaus Macherey and
               Jeff Klingner and
               Apurva Shah and
               Melvin Johnson and
               Xiaobing Liu and
               Lukasz Kaiser and
               Stephan Gouws and
               Yoshikiyo Kato and
               Taku Kudo and
               Hideto Kazawa and
               Keith Stevens and
               George Kurian and
               Nishant Patil and
               Wei Wang and
               Cliff Young and
               Jason Smith and
               Jason Riesa and
               Alex Rudnick and
               Oriol Vinyals and
               Greg Corrado and
               Macduff Hughes and
               Jeffrey Dean},
  title     = {Google's Neural Machine Translation System: Bridging the Gap between
               Human and Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1609.08144},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.08144},
  eprinttype = {arXiv},
  eprint    = {1609.08144},
  timestamp = {Thu, 14 Jan 2021 12:12:19 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/WuSCLNMKCGMKSJL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%29
@inproceedings{29_DBLP:conf/iccv/PlummerWCCHL15,
  author    = {Bryan A. Plummer and
               Liwei Wang and
               Chris M. Cervantes and
               Juan C. Caicedo and
               Julia Hockenmaier and
               Svetlana Lazebnik},
  title     = {Flickr30k Entities: Collecting Region-to-Phrase Correspondences for
               Richer Image-to-Sentence Models},
  booktitle = {2015 {IEEE} International Conference on Computer Vision, {ICCV} 2015,
               Santiago, Chile, December 7-13, 2015},
  pages     = {2641--2649},
  publisher = {{IEEE} Computer Society},
  year      = {2015},
  url       = {https://doi.org/10.1109/ICCV.2015.303},
  doi       = {10.1109/ICCV.2015.303},
  timestamp = {Wed, 16 Oct 2019 14:14:51 +0200},
  biburl    = {https://dblp.org/rec/conf/iccv/PlummerWCCHL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%30
@article{30_DBLP:journals/ijcv/PlummerWCCHL17,
  author    = {Bryan A. Plummer and
               Liwei Wang and
               Chris M. Cervantes and
               Juan C. Caicedo and
               Julia Hockenmaier and
               Svetlana Lazebnik},
  title     = {Flickr30k Entities: Collecting Region-to-Phrase Correspondences for
               Richer Image-to-Sentence Models},
  journal   = {Int. J. Comput. Vis.},
  volume    = {123},
  number    = {1},
  pages     = {74--93},
  year      = {2017},
  url       = {https://doi.org/10.1007/s11263-016-0965-7},
  doi       = {10.1007/s11263-016-0965-7},
  timestamp = {Fri, 13 Mar 2020 10:59:37 +0100},
  biburl    = {https://dblp.org/rec/journals/ijcv/PlummerWCCHL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%31
@article{31_DBLP:journals/ijcv/RussakovskyDSKS15,
  author    = {Olga Russakovsky and
               Jia Deng and
               Hao Su and
               Jonathan Krause and
               Sanjeev Satheesh and
               Sean Ma and
               Zhiheng Huang and
               Andrej Karpathy and
               Aditya Khosla and
               Michael S. Bernstein and
               Alexander C. Berg and
               Li Fei{-}Fei},
  title     = {ImageNet Large Scale Visual Recognition Challenge},
  journal   = {Int. J. Comput. Vis.},
  volume    = {115},
  number    = {3},
  pages     = {211--252},
  year      = {2015},
  url       = {https://doi.org/10.1007/s11263-015-0816-y},
  doi       = {10.1007/s11263-015-0816-y},
  timestamp = {Tue, 10 Jan 2023 08:57:16 +0100},
  biburl    = {https://dblp.org/rec/journals/ijcv/RussakovskyDSKS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%32
@inproceedings{32_DBLP:conf/cvpr/HeZRS16,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
  pages     = {770--778},
  publisher = {{IEEE} Computer Society},
  year      = {2016},
  url       = {https://doi.org/10.1109/CVPR.2016.90},
  doi       = {10.1109/CVPR.2016.90},
  timestamp = {Wed, 25 Jan 2023 11:01:16 +0100},
  biburl    = {https://dblp.org/rec/conf/cvpr/HeZRS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%33
@inproceedings{33_yin-etal-2020-novel,
    title = "A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation",
    author = "Yin, Yongjing  and
      Meng, Fandong  and
      Su, Jinsong  and
      Zhou, Chulun  and
      Yang, Zhengyuan  and
      Zhou, Jie  and
      Luo, Jiebo",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.273",
    doi = "10.18653/v1/2020.acl-main.273",
    pages = "3025--3035",
    abstract = "Multi-modal neural machine translation (NMT) aims to translate source sentences into a target language paired with images. However, dominant multi-modal NMT models do not fully exploit fine-grained semantic correspondences between semantic units of different modalities, which have potential to refine multi-modal representation learning. To deal with this issue, in this paper, we propose a novel graph-based multi-modal fusion encoder for NMT. Specifically, we first represent the input sentence and image using a unified multi-modal graph, which captures various semantic relationships between multi-modal semantic units (words and visual objects). We then stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions to learn node representations. Finally, these representations provide an attention-based context vector for the decoder. We evaluate our proposed encoder on the Multi30K datasets. Experimental results and in-depth analysis show the superiority of our multi-modal NMT model.",
}
%34
@inproceedings{34_DBLP:journals/corr/KingmaB14,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%35
@inproceedings{35_huang-etal-2016-attention,
    title = "Attention-based Multimodal Neural Machine Translation",
    author = "Huang, Po-Yao  and
      Liu, Frederick  and
      Shiang, Sz-Rung  and
      Oh, Jean  and
      Dyer, Chris",
    booktitle = "Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-2360",
    doi = "10.18653/v1/W16-2360",
    pages = "639--645",
}
%36
@inproceedings{36_calixto-etal-2017-doubly,
    title = "Doubly-Attentive Decoder for Multi-modal Neural Machine Translation",
    author = "Calixto, Iacer  and
      Liu, Qun  and
      Campbell, Nick",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1175",
    doi = "10.18653/v1/P17-1175",
    pages = "1913--1924",
    abstract = "We introduce a Multi-modal Neural Machine Translation model in which a doubly-attentive decoder naturally incorporates spatial visual features obtained using pre-trained convolutional neural networks, bridging the gap between image description and translation. Our decoder learns to attend to source-language words and parts of an image independently by means of two separate attention mechanisms as it generates words in the target language. We find that our model can efficiently exploit not just back-translated in-domain multi-modal data but also large general-domain text-only MT corpora. We also report state-of-the-art results on the Multi30k data set.",
}
%37
@inproceedings{37_elliott-kadar-2017-imagination,
    title = "Imagination Improves Multimodal Translation",
    author = "Elliott, Desmond  and
      K{\'a}d{\'a}r, {\'A}kos",
    booktitle = "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2017",
    address = "Taipei, Taiwan",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://aclanthology.org/I17-1014",
    pages = "130--141",
    abstract = "We decompose multimodal translation into two sub-tasks: learning to translate and learning visually grounded representations. In a multitask learning framework, translations are learned in an attention-based encoder-decoder, and grounded representations are learned through image representation prediction. Our approach improves translation performance compared to the state of the art on the Multi30K dataset. Furthermore, it is equally effective if we train the image prediction task on the external MS COCO dataset, and we find improvements if we train the translation model on the external News Commentary parallel text.",
}
%38
@inproceedings{38_calixto-etal-2019-latent,
    title = "Latent Variable Model for Multi-modal Translation",
    author = "Calixto, Iacer  and
      Rios, Miguel  and
      Aziz, Wilker",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1642",
    doi = "10.18653/v1/P19-1642",
    pages = "6392--6405",
    abstract = "In this work, we propose to model the interaction between visual and textual features for multi-modal neural machine translation (MMT) through a latent variable model. This latent variable can be seen as a multi-modal stochastic embedding of an image and its description in a foreign language. It is used in a target-language decoder and also to predict image features. Importantly, our model formulation utilises visual and textual inputs during training but does not require that images be available at test time. We show that our latent variable MMT formulation improves considerably over strong baselines, including a multi-task learning approach (Elliott and Kadar, 2017) and a conditional variational auto-encoder approach (Toyama et al., 2016). Finally, we show improvements due to (i) predicting image features in addition to only conditioning on them, (ii) imposing a constraint on the KL term to promote models with non-negligible mutual information between inputs and latent variable, and (iii) by training on additional target-language image descriptions (i.e. synthetic data).",
}

%39
@inproceedings{39_ive-etal-2019-distilling,
    title = "Distilling Translations with Visual Awareness",
    author = "Ive, Julia  and
      Madhyastha, Pranava  and
      Specia, Lucia",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1653",
    doi = "10.18653/v1/P19-1653",
    pages = "6525--6538",
    abstract = "Previous work on multimodal machine translation has shown that visual information is only needed in very specific cases, for example in the presence of ambiguous words where the textual context is not sufficient. As a consequence, models tend to learn to ignore this information. We propose a translate-and-refine approach to this problem where images are only used by a second stage decoder. This approach is trained jointly to generate a good first draft translation and to improve over this draft by (i) making better use of the target language textual context (both left and right-side contexts) and (ii) making use of visual context. This approach leads to the state of the art results. Additionally, we show that it has the ability to recover from erroneous or missing words in the source language.",
}
%40
@inproceedings{40_yao-wan-2020-multimodal,
    title = "Multimodal Transformer for Multimodal Machine Translation",
    author = "Yao, Shaowei  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.400",
    doi = "10.18653/v1/2020.acl-main.400",
    pages = "4346--4350",
    abstract = "Multimodal Machine Translation (MMT) aims to introduce information from other modality, generally static images, to improve the translation quality. Previous works propose various incorporation methods, but most of them do not consider the relative importance of multiple modalities. Equally treating all modalities may encode too much useless information from less important modalities. In this paper, we introduce the multimodal self-attention in Transformer to solve the issues above in MMT. The proposed method learns the representation of images based on the text, which avoids encoding irrelevant information in images. Experiments and visualization analysis demonstrate that our model benefits from visual information and substantially outperforms previous works and competitive baselines in terms of various metrics.",
}
%41
@article{41_DBLP:journals/corr/abs-2103-08862,
  author    = {Pengbo Liu and
               Hailong Cao and
               Tiejun Zhao},
  title     = {Gumbel-Attention for Multi-modal Machine Translation},
  journal   = {CoRR},
  volume    = {abs/2103.08862},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.08862},
  eprinttype = {arXiv},
  eprint    = {2103.08862},
  timestamp = {Tue, 23 Mar 2021 16:29:47 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-08862.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%42
@inproceedings{42_papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}
%43
@inproceedings{43_elliott-etal-2016-multi30k,
    title = "{M}ulti30{K}: Multilingual {E}nglish-{G}erman Image Descriptions",
    author = "Elliott, Desmond  and
      Frank, Stella  and
      Sima{'}an, Khalil  and
      Specia, Lucia",
    booktitle = "Proceedings of the 5th Workshop on Vision and Language",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-3210",
    doi = "10.18653/v1/W16-3210",
    pages = "70--74",
}
%44
@inproceedings{44_koehn-etal-2007-moses,
    title = "{M}oses: Open Source Toolkit for Statistical Machine Translation",
    author = "Koehn, Philipp  and
      Hoang, Hieu  and
      Birch, Alexandra  and
      Callison-Burch, Chris  and
      Federico, Marcello  and
      Bertoldi, Nicola  and
      Cowan, Brooke  and
      Shen, Wade  and
      Moran, Christine  and
      Zens, Richard  and
      Dyer, Chris  and
      Bojar, Ond{\v{r}}ej  and
      Constantin, Alexandra  and
      Herbst, Evan",
    booktitle = "Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P07-2045",
    pages = "177--180",
}
%45
@inproceedings{45_dyer-etal-2013-simple,
    title = "A Simple, Fast, and Effective Reparameterization of {IBM} Model 2",
    author = "Dyer, Chris  and
      Chahuneau, Victor  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N13-1073",
    pages = "644--648",
}
%46
@inproceedings{46_denkowski-lavie-2014-meteor,
    title = "Meteor Universal: Language Specific Translation Evaluation for Any Target Language",
    author = "Denkowski, Michael  and
      Lavie, Alon",
    booktitle = "Proceedings of the Ninth Workshop on Statistical Machine Translation",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-3348",
    doi = "10.3115/v1/W14-3348",
    pages = "376--380",
}
%47
@inproceedings{47_DBLP:conf/wmt/LibovickyHM18,
  author    = {Jindrich Libovick{\'{y}} and
               Jindrich Helcl and
               David Marecek},
  editor    = {Ondrej Bojar and
               Rajen Chatterjee and
               Christian Federmann and
               Mark Fishel and
               Yvette Graham and
               Barry Haddow and
               Matthias Huck and
               Antonio Jimeno{-}Yepes and
               Philipp Koehn and
               Christof Monz and
               Matteo Negri and
               Aur{\'{e}}lie N{\'{e}}v{\'{e}}ol and
               Mariana L. Neves and
               Matt Post and
               Lucia Specia and
               Marco Turchi and
               Karin Verspoor},
  title     = {Input Combination Strategies for Multi-Source Transformer Decoder},
  booktitle = {Proceedings of the Third Conference on Machine Translation: Research
               Papers, {WMT} 2018, Belgium, Brussels, October 31 - November 1, 2018},
  pages     = {253--260},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  url       = {https://doi.org/10.18653/v1/w18-6326},
  doi       = {10.18653/v1/w18-6326},
  timestamp = {Thu, 17 Feb 2022 16:43:16 +0100},
  biburl    = {https://dblp.org/rec/conf/wmt/LibovickyHM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%48
@inproceedings{48_DBLP:conf/aaai/WangX21,
  author    = {Dexin Wang and
               Deyi Xiong},
  title     = {Efficient Object-Level Visual Context Modeling for Multimodal Machine
               Translation: Masking Irrelevant Objects Helps Grounding},
  booktitle = {Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2021, Thirty-Third Conference on Innovative Applications of Artificial
               Intelligence, {IAAI} 2021, The Eleventh Symposium on Educational Advances
               in Artificial Intelligence, {EAAI} 2021, Virtual Event, February 2-9,
               2021},
  pages     = {2720--2728},
  publisher = {{AAAI} Press},
  year      = {2021},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/16376},
  timestamp = {Wed, 02 Jun 2021 18:09:11 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/WangX21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%---------------------------------------------------------------------------%

