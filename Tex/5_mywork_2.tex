\chapter{基于双向跨模态实体重构的神经机器翻译}

% 改进：
%    删去的：解码器、短语重构、目标端重构
%    增加的：文本->重构，句子级语义融合
%上一章提出了一种基于明确的图文实体替换的文本重构方法，该方法能够利用图片中视觉目标所携带的信息提升实体词的翻译准确率。虽然为整体的翻译准确率带来了一定的提升，但其一方面采用的是图片到文本单向的重构方法，相关研究表明由文本生成图像的过程也能够提升神经机器翻译的翻译质量；另一方面，原文到原文的生成过程将大量的训练资源浪费在将源端的单词复制到目标端，仅做到了将文本上下文信息融合到视觉目标对应的单词中，却难以将视觉信息融合到文本上下文中。
上一章提出了一种基于明确的图文实体替换的文本重构方法，该方法能够利用图片中视觉目标所携带的信息提升实体词的翻译准确率。虽然为整体的翻译准确率带来了一定的提升，但其一方面仅采用了图片到文本单向的重构方法，另一方面，原文到原文的生成过程将大量的训练资源浪费在将源端的单词复制到目标端，难以将视觉信息融合到文本上下文中。
%虽然有效，但模型也在学习复制过程，抛弃了图片信息与文本信息的相互融合。
为解决以上问题，本章提出了一种基于双向跨模态实体重构的神经机器翻译方法，并在训练中增加了将图片中视觉目标信息与文本上下文融合的任务。所提方法分为视觉目标到词的文本实体重构，文本到视觉目标的视觉实体重构，以及文本上下文与视觉目标组合到非实体词的文本非实体重构三个子任务。其能够更加充分地利用图片中所包含的视觉信息，从而提升神经机器翻译模型的翻译质量。
% 实验结果
实验结果展示了所提方法进一步提升翻译质量的能力，进一步的分析展示了方法的有效性。
\input{Tex/5_mywork_2/1_introduction}
% 应该强调一下多粒度跨模态信息融合方法，一个明确的粒度是实体机双向融合，另一个是句子级跨模态信息融合
\input{Tex/5_mywork_2/2_related_work}
% 应该侧重图片重建相关的方法，大概也就3个工作（imagination，Adversarial reconstruction for Multi-modal Machine Translation，

\input{Tex/5_mywork_2/3_method}
\input{Tex/5_mywork_2/4_setup}
% 实验结果中是否可以展示一下预测词正确的概率，能否与CTR相比下
\input{Tex/5_mywork_2/5_experiment_results}


\section{本章小结}
本文提出了一种跨模态实体重构方法用于探究以显式方式融合视觉信息与文本信息的可行性。在翻译性能方面，实验结果表明CER$-$NMT能够在英译德和英译法两个数据集上达到更高的翻译准确率。在消融实验中发现，视觉实体重构、文本实体重构以及文本非实体重构三种重构方法组合后NMT模型从视觉信息中获益最大。最后，本文尝试验证该显式方法的可解释性，实验结果表明跨模态实体重构方法显著地增加了模型对源端文本实体的忠实度，从而带来翻译质量的提升。