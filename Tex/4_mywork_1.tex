\chapter{基于跨模态文本重构的神经机器翻译}
% 本文应该侧重的是：
%    明确的视觉信息融合方式；
%    短语和词级别的视觉信息融合；
%    模型不需要对视觉信息敏感，因为视觉信息直接作用到目标上了

% 摘要
% 原文摘要：现有多模态机器翻译将视觉信息以全局特征的方式作为固定上下文输入，或者利用注意力机制对图像建立动态上下文作为文本内容的补充信息。然而这种隐含式的视觉信息融合方法对于分析图像如何起到作用以及为什么会产生作用带来了很大的挑战。针对此问题，提出了一种实体级的跨模态信息融合方法，显式地将文本中实体替换为对应图像中的视觉目标，并利用翻译模型来重建出完整的原文本，最后通过多任务的方式将以上重建任务与翻译任务相结合。实验表明，该方法在有效的提升了实体词的翻译质量，译文质量得到了显著的提升。
% 
%现有融入图片信息的神经机器翻译将视觉信息以全局特征的方式作为固定上下文输入，或者利用注意力机制对图像建立动态上下文作为文本内容的补充信息。然而这种隐含式的视觉信息融合方法对于分析图像如何起到作用以及为什么会产生作用带来了很大的挑战。针对此问题，提出了一种实体级的跨模态信息融合方法，显式地将文本中实体替换为对应图像中的视觉目标，并利用翻译模型来重建出完整的原文本，最后通过多任务的方式将以上重建任务与翻译任务相结合。实验表明，该方法在有效的提升了实体词的翻译质量，译文质量得到了显著的提升。

% 神经机器翻译中融合图片信息的问题：普遍范式中，句子与图片的信息融合是隐式的，即无法准确得知视觉信息作用到哪些词上或对句子的表示带来了哪些影响，因此，为了探索是否能够以明确的方式融合视觉信息，明确方式融入视觉信息是否对翻译有效，本章提出了一种在名词短语或名词的粒度上融合图片中的视觉目标信息，并进行跨模态文本重构的重构任务。再通过多任务训练的方式，将重构任务所优化的模型参数与翻译任务共享，从而达到提升翻译质量的目的。本章设置了进一步的分析实验，实验结果表明本章所提方法通过有效的提升实体词的翻译质量，从而提升了翻译准确率。

% 多模态的好处
采用分布式向量表示的神经翻译模型和图像处理基础模型极大地便利了以句子为基础语义单位的跨模态信息融合，
% 研究现状
例如，将视觉信息以全局特征的方式作为固定上下文输入到神经翻译模型中，或者利用注意力机制对图像建立动态上下文作为文本内容的补充信息。
% 存在的问题
然而句子与图片的信息融合是隐式的，即无法准确得知视觉信息作用到哪些词上或对句子的表示带来了哪些影响。
% 本章提出的方法
因此，为了探索是否能够以明确的方式融合视觉信息，以及明确方式融入视觉信息是否能够带来稳定的翻译质量提升，本章提出了一种在名词短语或名词的粒度上融合图片中的视觉目标信息，并进行跨模态文本重构的重构任务。通过多任务训练的方式，将重构任务所优化的模型参数与翻译任务共享，从而达到提升翻译质量的目的。
% 进一步的分析结果
本章设置了进一步的分析实验，实验结果表明本章所提方法通过有效的提升实体词的翻译质量，从而提升了翻译准确率。

\section{引言}

% 背景：
得益于神经网络方法的快速发展，自然语言处理和计算机视觉等领域均得到了飞速的进步，同时也为跨领域的信息融合带来了可能。在神经机器翻译中融合图片信息就是其中一种跨模态信息融合方法。跨模态的信息融合是为了解决一些在翻译中难以解决的问题，例如文本中存在歧义，表达不完整，文本表示欠拟合等问题。图片中往往包含着更丰富的语义信息。因此，如何将图片信息融合到翻译中成为了研究者们所关注的问题，相关方法也层出不穷。

% 相关研究：
目前已有的研究主要关注如何将整个图片中的信息融合到神经机器翻译模型的翻译过程中。由于图像分类任务所使用的卷积神经网络，如Resnet-50，取得了非常好的效果，因此多数研究这尝试将预训练的卷积神经网络与神经翻译模型相结合。例如一部分研究将图片经过卷积神经网络提取得到全局特征后，将其作为一个包含完整的上下文信息的特征向量以各种方式输入到翻译模型中，从而完善翻译模型在编码过程所获得的语义表征或为解码过程提供外源信息以供参考。文献【】尝试利用图片局部特征与注意力机制配合获图片的局部动态上下文,以达到在解码过程中融合与当前解码步骤最相关的视觉信息。此类方法中，图片作为一个句子级别的语义信息提供者作用到翻译过程中，试图使翻译模型最大化地利用图片中所包含的信息。
%因视觉信息与文本信息的融合与利用为通过模型学习的方式，而难以明确图片信息在翻译中的作用过程，本文称此类方法为隐式跨模态信息融合方法。

% 存在的问题：
然而，这些方法均以隐式的方式将图片信息与文本信息相结合，这些融合图片信息的神经机器翻译模型是如何应用视觉信息以及为何输入图片能够使得翻译性能提升都是不明确的，本文中，我们称此类方法为隐式跨模态信息融合方法。更重要的是，部分方法存在翻译质量提升不稳定的情况，不同的模型实现方案或不同的模型初始化条件下模型的翻译性能表现差异较大。尽管在句子级语义单位可以最大化地利用图片中所携带的视觉信息，但神经翻译模型似乎不能很顺利地将其利用。

% 本章提出方法
为此，本章提出了一种明确的图片信息融合方法。文献【】发现，当文本中部分内容或信息缺失，尤其是实体词缺失时，神经翻译模型对视觉信息最敏感。为了将图片中的视觉信息明确并有效地融合到模型中，本文以实体为语义单元融合图片信息，其中实体以短语实体或名词实体两种粒度呈现。区别于文献【】通过创造的文本内容缺失环境使隐式跨模态信息融合有效，本文采用显式跨模态信息融合方法，直接利用视觉特征替换实体作为模型输入，规避了神经翻译模型对视觉信息不敏感的问题。为了实现跨模态的信息融合，本文设计了一个重构模型来实现多模态输入到纯文本输出的任务。该模型以图片的视觉目标联合实体被替换的源语言文本为输入，以原文或译文为输出，通过端到端的学习将视觉目标中的视觉信息融合到实体的表示中。最后，本文利用了多任务学习方法，将跨模态文本重构任务与翻译任务相结合。通过多种参数共享机制，使翻译模型能够充分利用到重构任务重所学习到的视觉信息，从而提升翻译质量。

本章主要贡献如下：

（1）本章提出了一种基于跨模态文本重构的神经机器翻译方法(neural machine translation based on cross-modal text reconstruction, CTR-NMT), 并且将所提方法应用到了RNMT和Transformer两种框架。本章详细对比了多种参数共享方案，在推断（inference）时没有额外的图片输入的情况下，达到了与其它模型可比的翻译准确率。与纯文本基线模型相比，有着稳定的翻译质量的提升。

（2）本章提出了一种明确的融合图片信息的方法，即显式跨模态信息融合法。将图片中的视觉目标信息明确的作用到在文本中相对应的实体上，并在基于短语和基于词两种粒度的跨模态融合方案进行了实验对比，发现相比于短语实体，在词实体上融合图片信息效果更佳。

（3）本章对视觉目标的作用对象进行了分析，并发现本章所提的明确的图片信息作用方法，使名词实体的翻译准确率得到了更进一步的提升，从而提升了神经机器翻译模型的翻译质量。


\section{相关工作}

\section{方法描述}

\section{实验设置}

\section{实验结果}

\section{本章小结}
