\section{融合图片信息的神经机器翻译}
\label{sec:2_imgnmt}

%研究意义与背景介绍
得益于深度学习技术在自然语言理解和计算机视觉等领域的快速发展，融合文本与图片信息的跨模态理解与生成也成为了可能。融合图片信息的神经机器翻译就是将已经成熟的计算机视觉方法与神经机器翻译技术相结合的一类研究。其研究历程也紧随着纯文本神经机器翻译的脚步而发展。一个标准的神经机器翻译系统通常以句子为翻译单位。端到端的翻译模型通过拟合大量双语数据中语言之间的对齐特性习得翻译能力，在编码过程将源语言句子的信息编码为分布式的向量表示，再通过解码器将表示向量解码到目标语言。然而，针对翻译采集的数据也包含着人类语言应用中的使用习惯与问题。例如文本中存在多译词、歧义词或者不完整表达等问题，都需要通过待翻译句子以外的补充信息来解决，而图片中往往包含着更丰富、更完整以及更准确的信息。因此在翻译一个句子时，图片中的视觉信息能够其提供所需的外源补充信息。为此，研究者们提出了融合图片信息的神经机器翻译方法（image-incorporated neural machine translation，ImgNMT）。

% 任务定义
融合图片信息的神经机器翻译方法的目的是在基于神经机器翻译的框架内，借助图片信息生成更准确译文。该方法是多模态机器翻译（multi-modal machine translation）的一个研究子类。相关的多模态机器翻译还包含口语翻译\pcite{vida1997finite,ney1999speech,weiss2017sequence,berard2018end}（spoken language translation，SLT）和视频引导翻译\pcite{lison2016opensubtitles2016,sanabria2018how2,wang2019vatex}（video-guided translation，VGT）\pcite{sulubacak2020multimodal}。目前已知的多模态翻译方法多数是融合了两个模态信息的跨模态方法。视频引导翻译与融合图片信息的翻译任务有着相似的特点，都是在文本翻译的基础上通过融合视觉信息提升翻译性能，但也因此相关研究较少。

% 研究方法及其分类
作为多模态机器翻译领域的一个重要方向，ImgNMT得到了学界的广泛关注。2016年机器翻译研讨会（workshop on machine translation，WMT）开展多模态机器翻译的相关评测\pcite{specia2016shared}，彼时的多模态机器翻译任务的目标是为图片生成目标语言的译文，因此可分为两种解决方案：第一种是利用图片信息生成目标语言句子，这种任务形式一般称为图像描述生成（image captioning）或图像翻译；另一种就是在文本翻译任务中加入图片信息辅助翻译过程，也就是本文关注的ImgNMT。在此之后，WMT 2017\pcite{elliott2017findings}和WMT 2018\pcite{barrault2018findings}将多模态机器翻译的研究进一步推向全世界，越来越多的相关研究相继涌现。本节对融合图片信息的神经机器翻译的国内外研究现状进行了系统的梳理和分类。本文将相关研究分为四个类别：图片信息辅助式神经机器翻译、图片信息增强式神经机器翻译、基于图片搜索的神经机器翻译以及跨模态无监督神经机器翻译，并分别在后续的小节中进行详细的介绍。

%得益于神经网络方法的快速发展，自然语言文本与图片的信息融合成为了可能。融入图片信息的机器翻译的研究历程也紧随着纯文本的神经机器翻译的脚步而发展。然而，相关研究则最早起源于图像描述生成任务。有部分学者将文本作为一个外源信息来辅助图片描述的生成，但这种方式的本质则是在翻译任务中融入视觉信息。2016年WMT将多模态机器翻译引入作为共享任务后，MMT受到了广泛的关注。在之后的WMT17和WMT18，MMT任务延续并奠定了在机器翻译中融合图片信息作为多模态机器翻译研究的主要范式。

%平行翻译句一般具有良好的对齐特性，这使得融入的外源信息仅用于辅助少数具有歧义、信息不完整以及训练不充分等问题的句子的翻译。该特性也成为了展开相关研究道路上的一大难点。
%融合图片信息的神经机器翻译任务主要采用的是平行翻译句对加图片三元组形式的数据，即一张图片对应一句描述和一句翻译。大部分相关研究需要对神经机器翻译模型进行适当的修改，以适应图片的输入。模型中输入的图片可用于辅助优化翻译过程中源语言的语义表示，或为解码过程增加辅助外源信息。本文将这种在翻译过程中以源端文本作为信息主体，输入图片用于语义信息强化的方法称为图片信息辅助式神经机器翻译。可根据图片信息融合到翻译模型中的方式将这种方法分为三类：融合图片全局信息、融合图片局部动态信息以及融合图片视觉目标信息。这些三种图片信息以视觉特征为载体输入到翻译模型中，视觉特征则是从预训练的卷积神经网络中提取得到。不同的提取方式所包含的语义信息的粒度和特征维度有所不同。将这些不同形式的视觉特征整合到NMT模型后，模型进行跨模态语义融合的难易程度则取决于模型设计的合理性。


%以下两种方式合并讨论：
% 还可分为编码融合方法，和解码融合方法
% 全局 局部 视觉目标

% 显式、隐式：放到最后与igt和iet交叉讨论
\input{Tex/2_RelatedWork/4_1_visual_guided_MMT}
\input{Tex/2_RelatedWork/4_2_visual_enhanced_MMT}
\input{Tex/2_RelatedWork/4_3_retrival_based_MMT}
\input{Tex/2_RelatedWork/4_4_unsupervised_MMT}

