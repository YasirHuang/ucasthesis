\section{相关工作}

% 相关工作分类：
%     传统方法：句子级融合法，隐式法，（Feature-level Incongruence Reduction for Multimodal Translation，直接使用视觉特征不适合当前模型）
%     重构法：文本重构（Neural Machine Translation with Reconstruction，
%            图像重构（mywork2）（Imagination，Adversarial reconstruction for Multi-modal Machine Translation
%     实体替换法：主要用于分析
%     视觉目标法：
%     预训练模型法：包含纯文本预训练模型，毕竟消融实验中有类似的

% 这里可能需要提一下“退化文本”的概念

% 

本章工作主要目标是将图片中的视觉目标信息通过文本重构方法融合到文本的表示种，相关工作主要包含以下两个部分：

{\sffamily （1）融合视觉目标信息的神经机器翻译}

本文在\ref{sec:2_cv}小节中提到，在文本中融合图片信息的方式有很多种，其中采用图片中视觉目标信息的方式过滤掉了大部分无用的背景信息。
\tcite{huang2016attention}尝试了将图片中的多个视觉目标提取出来形成一个序列，拼接到源语言句子的词向量序列后面，再输入到模型中进行端到端的翻译。该工作还尝试将每个视觉目标与源语言句子单独进行编码的方案，然后采用注意力机制去关注与当前解码词最相关的那个编码序列，从而动态地利用视觉目标信息。
\tcite{yin2020novel}将句子与图片中的视觉目标视为图的关系，采用基于图的编码器融合跨模态信息。
\tcite{wang2021efficient}将视觉目标传递给翻译模型后，为了使模型利用到与文本内容相关的视觉信息并排除内容不相关的视觉信息，设计了目标掩码损失函数（object-masking loss）和视觉权重翻译损失函数（vision-weighted translation loss），分别在编码阶段和解码阶段针对文本的内容将视觉目标进行掩码或打分。

虽然采用视觉目标信息的方法能够避免引入大量的噪音信息，但是在文本信息和视觉信息融合的过程中，模型仍然需要学习如何主动地将图片中的有效信息整合到翻译的编码或解码过程中。然而，图片信息在这个过程中的具体作用并不清楚，信息融合的方式也是隐式的。与这些方法不同，本章采用了显式跨模态信息融合方法，直接将视觉目标信息应用到与之相关的单词或短语上。

{\sffamily （2）基于图片信息的文本生成}

融合图片信息的神经机器翻译任务与基于图片信息的文本生成任务素有渊源。基于图片信息的文本生成常指图片描述生成（image captioning）任务，即给定一张图片生成与图片内容相关的句子。\tcite{vinyals2015show}使用了一个基于长短时记忆网络（long short-term memory, LSTM）的编码器-解码器模型生成图片描述。该方法首先用一个卷积神经网络将图片编码成一个固定长度的向量，然后用一个LSTM将向量解码成一个自然语言句子。\tcite{xu2015show}和\tcite{lu2017knowing}进一步地在编码器-解码器模型中加入了注意力机制，使模型在解码的过程中能够动态地关注图片中的局部信息，从而生成更丰富的描述。从这些方法的特点中不难看出，融合图片信息的神经机器翻译方法从中得到了很多的启发。\tcite{kiros2014unifying}将图片描述生成定义为图片翻译任务，并在描述生成的过程中加入了源语言句子，因此与常规的融合图片信息的机器翻译方法相似。\tcite{calixto2017doubly}在文本注意力的基础上增加的图片注意力与图片描述生成所采用的方法相似。

%文献\cite{53_caglayan-etal-2019-probing}采用掩码的方式将源语言句子中的颜色、实体词和文本序列片段替换为没有明确含义的掩码词“<mask>”，从而得到退化文本（degrade text），然后在输入正确以及错误图片信息的情况下观察翻译模型的性能变化，发现当文本中缺失信息，尤其是实体词信息缺失时图片信息在模型中起了明显的作用。本章采用的基于图片信息的文本生成方法就是将视觉目标与退化文本相结合，并用结合后的多模态序列生成源语言或目标语言的文本。
\tcite{caglayan2019probing}通过使用掩码词“<mask>”替换源语言句子中的颜色、实体词和文本片段等关键信息，构造了退化文本（degraded text），然后分别在给定正确和错误的图片信息的条件下评估翻译模型的性能变化。结果表明，当文本中信息丢失时，特别是实体词信息丢失时，图片信息对模型性能的影响较大。本章采用了一种基于图片信息的文本生成方法，它将视觉目标与退化文本结合起来，并利用多模态序列生成源语言或目标语言的完整文本。


%目前，融合图片信息的神经机器翻译方法多采用将图片输入到翻译模型中辅助翻译过程的方式，但得到的翻译性能提升并不理想。相比之下，利用图片信息优化翻译模型参数进而增强翻译性能的方法取得了稳定且有效的提升。文献【】