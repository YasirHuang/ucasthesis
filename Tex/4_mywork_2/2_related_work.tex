\section{相关工作}
本章主要关注在图片增强式的神经机器翻译模型中，使用多种图文重构任务提升纯文本翻译质量。相关工作可以分为以下两类：

{\sffamily （1）图片重构}

图片不仅可以作为信息提供者为模型在翻译过程中提供需要补充的信息，也可以作为语义的参考媒介，帮助模型在训练过程中增强语义的表示能力。相对于句子到图像的生成问题，早期研究主要解决跨模态的语义对齐问题。\tcite{nakayama2017zero}将源语言句子、目标语言句子以及图片映射到一个统一的表示空间，在解码的过程中，解码器可以将来自不同模态的编码表示解码到目标语言句子。\tcite{chen2019from}认为图片相对于句子包含了更多与句子不相关的语义，难以直接作为句子级语义信息的媒介，因此提出了将图片作为词级翻译的媒介，并将词级翻译的结果应用到句子级的零资源翻译中。

以图片信息作为语义媒介的研究可以视为图片重构的先驱研究，因为这种语义的映射方式与利用句子生成图片的本质是相同的。然而，图片包含着比句子更完整且更丰富的信息。在面向翻译任务时，图片中大部分信息相对于待翻译的源语言句子实际上是冗余的。因此，在进行图片重构时，文本信息通常只能重构图片中的部分信息。\tcite{elliott2017imagination}为纯文本神经机器翻译设计了“想象力”机制。区别于直接生成与图片相对应的图片特征，该机制采用余弦相似度作为语义距离的衡量方法，拉近文本表示与图片特征的语义相似度。\tcite{zhou2018visual}在“想象力”机制的基础上增加了图像特征到文本的注意力机制，生成的上下文向量能够关注到与图片内容相关的源端词，通过初始化的方式将视觉信息提供给解码器。\tcite{long2021generative}采用生成对抗网络（generative adversarial networks，GAN）强化“想象力”机制。该方法使用注意力机制将源语言的词级表示用于生成与图片特征一致的向量表示，在解码阶段同样会使用到“想象”得到的特征向量，从而实现在编码阶段生成图片，在解码阶段利用生成的图片信息。

区别于上述这些方法利用句子级别的语义信息生成图片，本章所采用的视觉实体重构方法主要针对视觉目标的语义重构。一方面，图片中包含着相对于句子更多冗余的信息，这些冗余信息难以从句子的语义信息中重构；另一方面，视觉目标所包含的语义信息更集中，提取视觉目标的过程已经过滤掉大量的背景信息，使词到视觉目标的实体级重构更容易。


{\sffamily （2）视觉语言预训练方法}

图片信息与文本信息相融合的方法广泛应用于基于视觉语言预训练模型（vision-language pre-trained models）的自然语言理解任务（natural language understanding，NLU）中。
%文献【】采用了句子与图片的视觉目标序列的组合输入方式，在BERT的初始化参数基础上，通过对文本序列和视觉目标序列
常见方法采用BERT\pcite{devlin2019bert}与Faster R-CNN\pcite{ren2015faster}的组合方式，首先将输入图片输入到Faster R-CNN中提取多个视觉目标特征，然后将这些视觉目标特征当作图片序列同文本序列一起输入到以BERT为初始化参数的编码器中，最后通过多种预训练任务实现跨模态信息的融合\pcite{li2019visualbert,li2020unicodervl,su2020vlbert,chen2020uniter}。这其中常见的预训练任务有：（1）掩码语言模型（masked language modeling），该任务能够以文本为上下文，通过视觉目标所提供的视觉信息预测被掩码的单词，该过程能够将视觉信息融合到文本语义中；（2）图文匹配（image-text matching），该任务需要模型判断当前输入的句子和图片的内容是否一致。
\tcite{lu2019vilbert}和\tcite{tan2019lxmert}则采用了双流模型（dual-stream model）的结构，即图片和文本两个模态的序列需要各自编码再交叉编码的方式，试图通过模态内（intra-modality）和模态间（cross-modality）编码组合，加强跨模态信息融合的能力。
以上方法在使用视觉目标特征时，存在图片信息利用不充分的可能，为了将图片输入到模型时尽可能的保留全部的视觉信息，也可以放弃应用提取视觉目标的方案，将完整的图片或图片特征输入到了模型中\pcite{huang2020pixelbert,kim2021vilt,li2021align}。

区别于这些方法通过大量数据驱动的方式实现跨模态信息的融合，本章所提方法在文本非实体重构过程中使用视觉目标明确地替换文本中相对应的名词，而重构过程则是针对非实体词的重构。该过程虽然保留了显式的视觉信息作用方式，但在重构过程中使用视觉目标信息与文本上下文信息融合为跨模态上下文信息，在重构非实体词的过程中并非直接利用视觉目标的信息，因此文本非实体重构更满足隐式跨模态信息融合的特点。


% 文本到图片的翻译


% 多任务nlp，最好是翻译

% 预训练模型：文本、多模态

