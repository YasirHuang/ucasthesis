\section{实验结果}

\subsection{超参数$\omega$的影响}
对于本文所提的多任务学习方法，超参数$\omega$是一个影响最终翻译性能的重要参数。因此，本文首先依据该参数在英译德验证集上的BLEU值结果来选取一个合适的值。

如图3所示实验结果，横轴代表$\omega$从0.4以0.05为间隔增加至0.9，纵轴为NMT模型在英译德验证集上的BLEU值。该图反映出，当$\omega=0.7$时翻译模型的性能最佳。


\subsection{翻译结果}
表1显示了采用了CER方法的NMT系统的翻译结果。其中$\omega$按照4.1节的结论取值为0.7，对应的VER、TER和TNER三个子任务的训练比重分别为$12\%$、$12\%$和$6\%$。


表1中加粗项表示整列中的最佳结果。根据以上英译德和英译法的实验结果可以得到以下结论:

%\begin{itemize}
%\item
1）本文所提方法在Multi30K Test2016测试集的两种语言对上取得了BLEU和METEOR的最佳性能，并且在Test2017测试集上的结果超过了多数模型的结果，并与其它模型的最佳结果相比差距很小。这说明CER方法能够有效提升NMT模型的翻译质量。

%\item
2）CER$-$NMT在歧义词较多的Ambiguous MSCOCO上的表现落后于GMMT和EMMT两个模型。这是因为CER方法主要帮助NMT在训练阶段融合视觉信息，在测试阶段因为不需要输入图像使得模型无法借助视觉信息解决歧义词的问题。

3）%\item
GMMT、EMMT和CER$-$NMT同为实体级方法，结果均优于传统方法。这说明NMT模型融入更细粒度的视觉信息时效果更好，传统句子级方法对视觉信息利用效率较差。
%\end{itemize}

综合以上的实验结果，本文所提的跨模态实体重构方法能有效地提升机器翻译的质量。

\subsection{消融实验}
为了探究VER、TER和TNER三个子任务对CER$-$NMT模型的影响，本节设置了12组消融实验。其中序号0代表4.2节中CER-NMT的结果。序号1$-$3组各去掉一个子任务，并保持剩余子任务的训练权重。序号4$-$5组各去掉一个子任务，保持NMT的权重。序号7$-$9组各保留一个子任务，保持子任务的权重。序号10$-$12组保留一个子任务，保持NMT的权重。

实验结果如表2所示，其中“-”代表所对应的子任务被去掉，可以获得如下信息:


%\begin{itemize}
%\item
1）序号1$-$6组与序号7$-$12组对比可以看出，子任务组合的方式要优于仅使用单一子任务。其中，VER和TER的组合已经可以使NMT达到很好的结果。TNER对NMT的影响最小，但是依旧可以为NMT模型带来小幅度的提升。

%\item
2）$\omega>0.8$的实验组结果与4.1节中的实验结果均说明减少跨模态任务至一定比重后，模型的性能将逐渐趋近于NMT。

%\item
3）与4.2节中CER$-$NMT的结果相比可以说明，VER、TER和TNER三个子任务共同配合可以使NMT的性能达到最佳。
%\end{itemize}


\subsection{文本实体忠实度}

本文所提方法主要将视觉信息与文本实体相融合，这使得视觉信息具有更明确的作用方向。因此检验视觉信息是否对文本实体的翻译产生了影响成为了一个必要的环节。本文尝试测量在解码生成目标单词时对文本实体的忠实度来反映模型的行为变化。

Transformer的解码器采用的是交叉注意力机制，与一般的注意力机制类似的是，在解码过程中通过给源端的词不同的“权重”来达到“关注”或“忽视”的作用。该“权重”体现了当前要解码的目标端单词对源端单词所提供信息的需求程度。因此，本文选择Transformer解码器最后一层交叉注意力权重的多头平均值为生成目标端词时对源端词的注意力“权重”，并定义该“权重”为忠实度（Fidelity），用于量化生成目标端文本实体时对源端文本实体的忠实程度。2.1节中提到，源端的文本实体是通过文本分析工具spaCy提取得到。本节中所要确定的目标端文本实体是通过fast$-$align[38]对齐工具对齐源端与目标端单词得到的。为了得到一个较好的对齐结果，笔者将测试集与训练集拼接后训练对齐模型。

实验结果如图4所示，图中横轴代表测试集中源端文本实体以某种方式的排序，纵轴为范围从0到1的忠实度。每个小像素点代表一个源端文本实体在一个翻译句子样本中对应目标端文本实体的注意力权重值，即实体词忠实度。大圆点代表每个实体的平均忠实度。图（a）为纯文本Transformer的测试结果，横轴为测试集中的1110个源端文本实体按照平均忠实度由小到大排序。图（b）和（c）为CER$-$NMT的结果，其中（b）的横轴排序与（a）保持一致。图（d）为4.3节序号12仅设置TNER的模型。图中“avg”代表平均值。从4个图的对比中可以得到以下信息：

%\item
1）图中忠实度为0的横线部分代表对齐模型无法在目标端句子中找到对应的实体词。因此无法确定其忠实度。

%\item
2）图（b）相比于图（a）存在更多靠近1.0的小像素点。从图（c）中的均值结果（avg）可以看到，小像素点的均值从0.4238提升至0.4498，大圆点的均值从0.4024提升至0.4478，均具有较明显的提升。该数值结果表明CER方法能够明显地提升NMT在翻译过程中对源端文本实体的忠实度。

%\item
3）图（c）经过重排序实体的顺序后可以更直观地从曲线的趋势看出采用CER方法所带来的忠实度的提升。

%\item
4）TNER对文本上下文和视觉实体进行句子级的语义融合，可以观察到图（d）相对于图（a）有提升也有降低，这说明VER和TER才是帮助提升文本实体忠实度的主要因素，非实体重构方法所带来的翻译性能提升无法带来显著的实体忠实度的提升。
%\end{itemize}


以上结果表明，CER通过融入视觉信息的方式，增加了翻译模型在翻译过程中对源端文本实体的忠实度，从而使得翻译结果得到了进一步的提升。该实验同样表明本文所提的显式融合视觉信息的方式是有效可行的，该显式方法使得模型更具备可解释性，视觉信息的作用方式更有迹可循。