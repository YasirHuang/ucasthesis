\section{引言}
%第一部分应该讲一些能够引入sec3不足的方面，即如何更充分的利用视觉信息
%可以从预训练模型的角度去分析仅采用一种task的方式的不足
%本章可以强调多任务的“多”，上一章更应该是双任务
传统的融合图片信息的神经机器翻译方法采取将图片作为额外输入，从而使翻译模型在编码或解码阶段尽可能地利用其所携带的信息。然而这类方法很难达到理想的效果，图片作为外源信息难以被直接利用。相比之下，采用多任务学习的方式将外源信息融合到神经机器翻译中是一种可行的方案\cite{49_wang-zhang-2022-addressing,50_kang_zong_2022}。


%第二部分从上一章做了哪些具体内容，详细分析其不足，例如为何重构文本存在资源浪费，为何只有文本上下文到视觉目标的融合。
上一章提出的跨模态文本重构方法采用了文本重构任务，尝试在跨模态编码和文本解码生成两个阶段将图片中的视觉目标信息融合到词的表示中，并为模型的翻译质量带来了提升。但该方法仍存在着一定的不足和需要改进的地方：一是所采用的重构方案是单向的，仅考虑了图片到文本方向，文献【】表明文本到图像的生成同样可以提升模型的翻译质量，因此存在未充分利用视觉信息的可能；二是原文到原文的生成训练，很容易让模型的编码-解码过程收敛为“复制-粘贴”过程，这种极端情况下除了视觉目标对应位置可以从图片以及上下文中获取信息用于生成目标单词，其它词在编码和解码过程中并不会融合信息，只是将源语言的词复制并粘贴到目标端的对应位置，使整个重构模型的训练流程大量地浪费在这种“复制-粘贴”过程中。
尽管模型的实际表现并未如此不堪，但以上的分析也说明了方法存在的改进空间。

%如何解决上面的不足：双向重构（文到图的重构会带来哪些作用），文本非实体重构（为何将视觉信息融合到文本中有效果）（这两个问题需要在实验中体现）
为了解决以上问题，本章提出一种跨模态实体重构（cross-modal entity reconstruction，CER）方法用于帮助神经机器翻译提升译文的质量。该方法为了更加充分地将图片中的视觉目标信息融合到实体词的表示中，采取了图片与文本两个模态之间的双向重构策略。并且为了进一步提升图片信息的作用，将图片信息与文本上下文信息融合，采用了非实体的重构策略。
具体地，CER方法分为三个子任务：
文本实体重构任务延续了上一章文本重构任务利用视觉目标与文本上下文实现重构的策略，区别在于文本实体重构任务省去了非实体词的生成过程；
视觉实体重构任务负责从文本上下文与文本实体中所提供的文本模态信息重构视觉目标实体，区别于重构完整图片的方案，视觉实体重构以更细粒度更精确的方式进行文本到图像的生成任务；
文本非实体重构任务采用部分文本上下文信息与视觉实体的组合，重构文本上下文中非实体词的部分，这样能够使图片中的视觉目标信息作用到文本的表示学习过程中。
CER-NMT是结合了跨模态实体重构方法的神经机器翻译方法。在CER-NMT中，翻译任务作为主任务与CER方法的三个子任务通过多任务训练的方式相结合，并达到提升模型的翻译准确率的目的。

%贡献：实体级图片重构，显式方法与隐式方法的融合，
本章主要贡献如下：

（1）本章提出了一种基于双向跨模态实体重构的神经机器翻译方法。在文本重构任务的基础上，增加了视觉实体重构和文本非实体重构两个任务，使图片中的视觉目标信息能够更充分的融合到文本的表示中，从而为翻译模型带来翻译质量的提升。
%使得在文本的表示学习过程中图片中的视觉目标信息能够更充分地融合到

（2）本章所提方法结合了显式与隐式两种跨模态信息融合方法。文本实体重构与视觉实体重构均采用了显式跨模态实体信息融合方法，即图片信息具有明确的作用目标。文本非实体重构采用了视觉信息与文本上下文信息，因为非实体词与视觉目标没有直接的对应关系，因此视觉信息的作用目标不明确，属于隐式跨模态信息融合方法。

（3）本章所提方法使模型的翻译质量得到了进一步的提升。在对实验结果的分析中发现，CER方法能够提升模型的翻译忠实度。