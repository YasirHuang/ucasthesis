\chapter{基于跨模态文本重构的神经机器翻译}
% 本文应该侧重的是：
%    明确的视觉信息融合方式；
%    短语和词级别的视觉信息融合；
%    模型不需要对视觉信息敏感，因为视觉信息直接作用到目标上了

% 摘要
% 原文摘要：现有多模态机器翻译将视觉信息以全局特征的方式作为固定上下文输入，或者利用注意力机制对图像建立动态上下文作为文本内容的补充信息。然而这种隐含式的视觉信息融合方法对于分析图像如何起到作用以及为什么会产生作用带来了很大的挑战。针对此问题，提出了一种实体级的跨模态信息融合方法，显式地将文本中实体替换为对应图像中的视觉目标，并利用翻译模型来重建出完整的原文本，最后通过多任务的方式将以上重建任务与翻译任务相结合。实验表明，该方法在有效的提升了实体词的翻译质量，译文质量得到了显著的提升。
% 
%现有融入图片信息的神经机器翻译将视觉信息以全局特征的方式作为固定上下文输入，或者利用注意力机制对图像建立动态上下文作为文本内容的补充信息。然而这种隐含式的视觉信息融合方法对于分析图像如何起到作用以及为什么会产生作用带来了很大的挑战。针对此问题，提出了一种实体级的跨模态信息融合方法，显式地将文本中实体替换为对应图像中的视觉目标，并利用翻译模型来重建出完整的原文本，最后通过多任务的方式将以上重建任务与翻译任务相结合。实验表明，该方法在有效的提升了实体词的翻译质量，译文质量得到了显著的提升。

% 神经机器翻译中融合图片信息的问题：普遍范式中，句子与图片的信息融合是隐式的，即无法准确得知视觉信息作用到哪些词上或对句子的表示带来了哪些影响，因此，为了探索是否能够以明确的方式融合视觉信息，明确方式融入视觉信息是否对翻译有效，本章提出了一种在名词短语或名词的粒度上融合图片中的视觉目标信息，并进行跨模态文本重构的重构任务。再通过多任务训练的方式，将重构任务所优化的模型参数与翻译任务共享，从而达到提升翻译质量的目的。本章设置了进一步的分析实验，实验结果表明本章所提方法通过有效的提升实体词的翻译质量，从而提升了翻译准确率。

% 多模态的好处
采用分布式向量表示的神经翻译模型和计算机视觉基础模型极大地便利了以句子为基本语义单位的跨模态信息融合，
% 研究现状
例如，将图片以全局特征的方式作为固定上下文输入到神经翻译模型中，或者利用注意力机制对图像建立动态上下文作为文本内容的补充信息。
% 存在的问题
然而在这些方法中，句子与图片的信息融合是隐式的，即无法准确得知视觉信息作用到哪些词上或对句子的表示带来了哪些影响。
% 本章提出的方法
因此，为了探索是否能够以显式的方式融合视觉信息，以及显式方式融入视觉信息是否能够带来稳定的翻译质量提升，本章提出了在词级和短语级融合图片中的视觉目标信息，并进行跨模态文本重构的重构任务。通过多任务训练的方式，将文本重构任务所优化的模型参数与翻译任务共享，从而达到提升翻译质量的目的。
% 进一步的分析结果
%本章设置了进一步的分析实验，实验结果表明本章所提方法通过有效地提升实体词的翻译质量，从而提升了翻译准确率。
本章设置了进一步的分析实验，实验结果表明所提方法对实体词的翻译有更好的提升效果，从而提升了译文的质量。

\input{Tex/3_mywork_1/1_introduction.tex}
\input{Tex/3_mywork_1/2_related_work.tex}
\input{Tex/3_mywork_1/3_background_knowledge.tex}
\input{Tex/3_mywork_1/4_method.tex}
\input{Tex/3_mywork_1/5_setup.tex}
\input{Tex/3_mywork_1/6_experiment_results.tex}

\section{本章小结}
为了探究显式跨模态信息融合方法的可行性，本章提出了采用明确的方式将文本中的名词或名词短语替换为图片中相对应的视觉目标。然后将该方法应用于文本句子的重构任务，再通过参数共享的方式，将重构模型优化后的模型参数与翻译模型共享，从而增强了神经机器翻译系统的翻译性能。
该方法在融合图片信息的机器翻译任务常用的Multi30K英德翻译数据集上进行了实验，在测试阶段不需要输入图片的情况下，在基于循环神经网络的模型中取得了最佳的翻译效果，在基于Transformer的模型上与其它模型仍然是可比的。
在消融与对抗训练的实验中，输入原图片的模型性能优于输入随机噪声或不输入图片的掩码方案。说明文本重构模型通过利用图片信息优化了模型的参数，使翻译模型得到了增强。
在进一步的实验分析中发现，本章所提方法主要提升了实体词的翻译准确率，从而在整体上提升了译文的质量。

该研究成果发表于2021年自然语言处理实证方法会议（EMNLP 2021）。

%为了探究显式跨模态信息融合的可行性，本章提出了一种以明确的方式将图片中的视觉目标信息与文本中对应的短语实体或词实体相融合的方法。并将该方法应用于文本的重构任务，最后通过多任务参数共享的方式，优化了翻译模型中对实体词的翻译能力，从而带来了进一步翻译质量的提升。实验结果表明，所提方法在测试阶段不需输入图片信息的条件下依旧与其它需要输入图片的方法是可比的，并且对词实体的翻译具有显著的提升作用。该研究成果发表于Findings of the Association for Computational Linguistics: EMNLP 2021。