% 这个章节中可以多提一下ImgNMT与多模态摘要任务的区别
\section{图片信息辅助式神经机器翻译}
得益于神经网络方法的快速发展，自然语言文本与图片的信息融合成为了可能。融入图片信息的机器翻译的研究历程也紧随着纯文本的神经机器翻译的脚步而发展。然而，相关研究则最早起源于图像描述生成任务。有部分学者将文本作为一个外源信息来辅助图片描述的生成，但这种方式的本质则是在翻译任务中融入视觉信息。2016年WMT将多模态机器翻译引入作为共享任务后，MMT受到了广泛的关注。在之后的WMT17和WMT18，MMT任务延续并奠定了在机器翻译中融合图片信息作为多模态机器翻译研究的主要范式。

%平行翻译句一般具有良好的对齐特性，这使得融入的外源信息仅用于辅助少数具有歧义、信息不完整以及训练不充分等问题的句子的翻译。该特性也成为了展开相关研究道路上的一大难点。
融合图片信息的神经机器翻译任务主要采用的是平行翻译句对加图片三元组形式的数据，即一张图片对应一句描述和一句翻译。大部分相关研究需要对神经机器翻译模型进行适当的修改，以适应图片的输入。模型中输入的图片可用于辅助优化翻译过程中源语言的语义表示，或为解码过程增加辅助外源信息。本文将这种在翻译过程中以源端文本作为信息主体，输入图片用于语义信息强化的方法称为图片信息辅助式神经机器翻译。可根据图片信息融合到翻译模型中的方式将这种方法分为三类：融合图片全局信息、融合图片局部动态信息以及融合图片视觉目标信息。这些三种图片信息以视觉特征为载体输入到翻译模型中，视觉特征则是从预训练的卷积神经网络中提取得到。不同的提取方式所包含的语义信息的粒度和特征维度有所不同。将这些不同形式的视觉特征整合到NMT模型后，模型进行跨模态语义融合的难易程度则取决于模型设计的合理性。

\subsection{融合图片全局信息的神经机器翻译}

\cite{18_DBLP:conf/emnlp/CalixtoL17}
\cite{19_DBLP:conf/acl/CalixtoRA19}
\cite{20_DBLP:conf/acl/WuKBLK20}


\subsection{融合图片局部动态信息的神经机器翻译}

\subsection{融合图片视觉目标信息的神经机器翻译}


