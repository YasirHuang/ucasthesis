\section{引言}
% 背景：
得益于神经网络方法的快速发展，自然语言处理和计算机视觉等领域均得到了飞速的进步，同时也为跨领域的信息融合带来了可能。在神经机器翻译中融合图片信息就是其中一种跨模态信息融合方法。跨模态的信息融合是为了解决一些在翻译中难以解决的问题，例如文本中存在歧义，表达不完整，文本表示欠拟合等问题。图片中往往包含着更丰富的语义信息。因此，如何将图片信息融合到翻译中成为了研究者们所关注的问题，相关方法也层出不穷。

% 相关研究：
目前已有的研究主要关注如何将整个图片中的信息融合到神经机器翻译模型的翻译过程中。由于图像分类任务所使用的卷积神经网络，如Resnet-50\cite{32_DBLP:conf/cvpr/HeZRS16}，取得了非常好的效果，因此多数研究这尝试将预训练的卷积神经网络与神经翻译模型相结合。例如部分研究将图片经过卷积神经网络提取得到全局特征后，将其作为一个包含完整的上下文信息的特征向量以各种方式输入到翻译模型中，从而完善翻译模型在编码过程所获得的语义表征或为解码过程提供外源信息以供参考\cite{52_DBLP:journals/corr/ElliottFH15,18_DBLP:conf/emnlp/CalixtoL17,22_li-etal-2021-vision,20_wu-etal-2021-good}。
文献\cite{36_calixto-etal-2017-doubly,47_DBLP:conf/wmt/LibovickyHM18}尝试利用图片局部特征与注意力机制配合获图片的局部动态上下文,以达到在解码过程中融合与当前解码步骤最相关的视觉信息。此类方法中，图片作为一个句子级别的语义信息提供者作用到翻译过程中，试图使翻译模型最大化地利用图片中所包含的信息。
%因视觉信息与文本信息的融合与利用为通过模型学习的方式，而难以明确图片信息在翻译中的作用过程，本文称此类方法为隐式跨模态信息融合方法。

% 存在的问题：
然而，这些方法均以隐式的方式将图片信息与文本信息相结合，这些融合图片信息的神经机器翻译模型是如何应用视觉信息以及为何输入图片能够使得翻译性能提升都是不明确的，本文中，我们称此类方法为隐式跨模态信息融合方法。更重要的是，部分方法存在翻译质量提升不稳定的情况，不同的模型实现方案或不同的模型初始化条件下模型的翻译性能表现差异较大。尽管在句子级语义单位可以最大化地利用图片中所携带的视觉信息，但神经翻译模型似乎不能很顺利地将其利用。

% 本章提出方法
为此，本章提出了一种明确的图片信息融合方法。文献\cite{53_caglayan-etal-2019-probing}发现，当文本中部分内容或信息缺失，尤其是实体词缺失时，神经翻译模型对视觉信息最敏感。为了将图片中的视觉信息明确并有效地融合到模型中，本文以实体为语义单元融合图片信息，其中实体以短语实体或名词实体两种粒度呈现。区别于文献\cite{53_caglayan-etal-2019-probing}通过创造的文本内容缺失环境使隐式跨模态信息融合有效，本文采用显式跨模态信息融合方法，直接利用视觉特征替换实体作为模型输入，规避了神经翻译模型对视觉信息不敏感的问题。为了实现跨模态的信息融合，本文设计了一个重构模型来实现多模态输入到纯文本输出的任务。该模型以图片的视觉目标联合实体被替换的源语言文本为输入，以原文或译文为输出，通过端到端的学习将视觉目标中的视觉信息融合到实体的表示中。最后，本文利用了多任务学习方法，将跨模态文本重构任务与翻译任务相结合。通过多种参数共享机制，使翻译模型能够充分利用到重构任务重所学习到的视觉信息，从而提升翻译质量。

本章主要贡献如下：

（1）本章提出了一种基于跨模态文本重构的神经机器翻译方法(neural machine translation based on cross-modal text reconstruction, CTR-NMT), 并且将所提方法应用到了RNMT和Transformer两种框架。本章详细对比了多种参数共享方案，在推断（inference）时没有额外的图片输入的情况下，达到了与其它模型可比的翻译准确率。与纯文本基线模型相比，有着稳定的翻译质量的提升。

（2）本章提出了一种明确的融合图片信息的方法，即显式跨模态信息融合法。将图片中的视觉目标信息明确的作用到在文本中相对应的实体上，并在基于短语和基于词两种粒度的跨模态融合方案进行了实验对比，发现相比于短语实体，在词实体上融合图片信息效果更佳。

（3）本章对视觉目标的作用对象进行了分析，并发现本章所提的明确的图片信息作用方法，使名词实体的翻译准确率得到了更进一步的提升，从而提升了神经机器翻译模型的翻译质量。
